import json
import urllib.request
import urllib.parse
import uuid
import time
import io
import os
from datetime import datetime
from pathlib import Path

import requests
import urllib.error
import cv2
import numpy as np
from basicsr.archs.rrdbnet_arch import RRDBNet
from realesrgan import RealESRGANer
from PIL import Image

from requests import Timeout


class ComfyUIClient:
    def __init__(self, server_address="127.0.0.1:18188"):
        self.server_address = server_address
        self.client_id = str(uuid.uuid4())

    def queue_prompt(self, prompt):
        """Envoie le workflow √† la queue ComfyUI"""
        p = {"prompt": prompt, "client_id": self.client_id}
        data = json.dumps(p).encode('utf-8')
        req = urllib.request.Request(
            f"http://{self.server_address}/prompt",
            data=data,
            headers={"Content-Type": "application/json"}
        )
        try:
            with urllib.request.urlopen(req) as resp:
                return json.loads(resp.read())
        except urllib.error.HTTPError as e:
            body = e.read().decode("utf-8", errors="ignore")
            raise RuntimeError(f"ComfyUI /prompt ‚Üí HTTP {e.code} {e.reason}\n{body}") from e

    def get_image(self, filename, subfolder, folder_type):
        """R√©cup√®re une image g√©n√©r√©e"""
        data = {"filename": filename, "subfolder": subfolder, "type": folder_type}
        url_values = urllib.parse.urlencode(data)
        with urllib.request.urlopen(f"http://{self.server_address}/view?{url_values}") as response:
            return response.read()

    def get_history(self, prompt_id):
        """R√©cup√®re l'historique d'une g√©n√©ration"""
        with urllib.request.urlopen(f"http://{self.server_address}/history/{prompt_id}") as response:
            return json.loads(response.read())

    def get_node_mappings(self):
        """R√©cup√®re les mappings des n≈ìuds disponibles"""
        try:
            with urllib.request.urlopen(f"http://{self.server_address}/object_info") as response:
                return json.loads(response.read())
        except Exception as e:
            print(f"Erreur lors de la r√©cup√©ration des n≈ìuds: {e}")
            return {}

    def get_installed_custom_nodes(self):
        """R√©cup√®re la liste des custom nodes install√©s"""
        try:
            with urllib.request.urlopen(f"http://{self.server_address}/customnode/getmappings") as response:
                data = json.loads(response.read())
                return data
        except Exception as e:
            print(f"Info: Impossible de r√©cup√©rer la liste des custom nodes: {e}")
            return {}

    def install_custom_node(self, node_url):
        """Installe un custom node via git"""
        try:
            data = json.dumps({"url": node_url}).encode('utf-8')
            req = urllib.request.Request(
                f"http://{self.server_address}/customnode/install",
                data=data,
                headers={'Content-Type': 'application/json'}
            )
            with urllib.request.urlopen(req) as response:
                return json.loads(response.read())
        except Exception as e:
            print(f"Erreur lors de l'installation du n≈ìud: {e}")
            return None

    def upload_image(self, image_path):
        """Upload une image vers ComfyUI"""
        with open(image_path, 'rb') as f:
            files = {'image': (image_path, f, 'image/png')}
            data = {'overwrite': 'true'}

            boundary = '----WebKitFormBoundary' + str(uuid.uuid4()).replace('-', '')
            body = io.BytesIO()

            body.write(f'--{boundary}\r\n'.encode())
            body.write(f'Content-Disposition: form-data; name="image"; filename="{image_path}"\r\n'.encode())
            body.write(b'Content-Type: image/png\r\n\r\n')
            body.write(f.read())
            body.write(b'\r\n')

            body.write(f'--{boundary}\r\n'.encode())
            body.write(b'Content-Disposition: form-data; name="overwrite"\r\n\r\n')
            body.write(b'true\r\n')
            body.write(f'--{boundary}--\r\n'.encode())

            req = urllib.request.Request(
                f"http://{self.server_address}/upload/image",
                data=body.getvalue(),
                headers={'Content-Type': f'multipart/form-data; boundary={boundary}'}
            )

            with urllib.request.urlopen(req) as response:
                return json.loads(response.read())

    def wait_for_completion(self, prompt_id, check_interval=1):
        """Attend la fin de la g√©n√©ration"""
        while True:
            history = self.get_history(prompt_id)
            if prompt_id in history:
                return history[prompt_id]
            time.sleep(check_interval)


class VideoUpscaler:
    def __init__(self, model_name='RealESRGAN_x4plus', device='cuda'):
        """
        Initialise l'upscaler RealESRGAN
        
        Args:
            model_name: 'RealESRGAN_x2plus', 'RealESRGAN_x3plus', ou 'RealESRGAN_x4plus'
            device: 'cuda' ou 'cpu'
        """
        self.model_name = model_name
        self.device = device
        self.upsampler = self._init_upscaler()

    def _init_upscaler(self):
        """Initialise le mod√®le RealESRGAN"""
        scale = 2

        model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=scale)
        
        upsampler = RealESRGANer(
            scale=scale,
            model_path='https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.1/RealESRGAN_x2plus.pth',
            model=model,
            tile=400,
            tile_pad=10,
            pre_pad=0,
            half=self.device == 'cuda'
        )
        
        return upsampler

    def upscale_frame(self, frame):
        """
        Upscale une frame individuelle
        
        Args:
            frame: numpy array (H, W, 3) en BGR
        
        Returns:
            Frame upscal√©e (numpy array)
        """
        output, _ = self.upsampler.enhance(frame, outscale=1)
        return output

    def upscale_video(self, input_video_path, output_video_path, target_resolution=None):
        """
        Upscale une vid√©o compl√®te
        
        Args:
            input_video_path: Chemin de la vid√©o d'entr√©e
            output_video_path: Chemin de la vid√©o de sortie
            target_resolution: Tuple (width, height) ou None pour garder le ratio
        """
        # Ouverture de la vid√©o
        cap = cv2.VideoCapture(input_video_path)
        
        fps = cap.get(cv2.CAP_PROP_FPS)
        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        print(f"Vid√©o d'entr√©e: {original_width}x{original_height} @ {fps}fps ({frame_count} frames)")
        
        # Lecture premi√®re frame pour obtenir la r√©solution upscal√©e
        ret, first_frame = cap.read()
        if not ret:
            raise RuntimeError("Impossible de lire la vid√©o")
        
        upscaled_frame = self.upscale_frame(first_frame)
        upscaled_height, upscaled_width = upscaled_frame.shape[:2]
        
        # Si r√©solution cible sp√©cifi√©e, redimensionner
        if target_resolution:
            target_width, target_height = target_resolution
            upscaled_frame = cv2.resize(upscaled_frame, (target_width, target_height), interpolation=cv2.INTER_LANCZOS4)
            upscaled_width, upscaled_height = target_width, target_height
        
        print(f"Vid√©o de sortie: {upscaled_width}x{upscaled_height} @ {fps}fps")
        
        # Cr√©ation du writer
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_video_path, fourcc, fps, (upscaled_width, upscaled_height))
        
        # R√©initialisation du capture
        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
        
        frame_num = 0
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # Upscale
            upscaled = self.upscale_frame(frame)
            
            # Redimensionnement si n√©cessaire
            if target_resolution:
                upscaled = cv2.resize(upscaled, (target_width, target_height), interpolation=cv2.INTER_LANCZOS4)
            
            # Conversion en uint8 si n√©cessaire
            if upscaled.dtype != np.uint8:
                upscaled = np.clip(upscaled, 0, 255).astype(np.uint8)
            
            out.write(upscaled)
            
            frame_num += 1
            if frame_num % 10 == 0:
                print(f"  Upscal√© {frame_num}/{frame_count} frames ({100*frame_num/frame_count:.1f}%)")
        
        cap.release()
        out.release()
        print(f"Upscaling termin√©: {output_video_path}")


def create_workflow(
        positive_prompt,
        negative_prompt,
        input_image="4.png",
        resolution=480,
        length=81
):
    """Cr√©e le workflow avec les param√®tres configurables - TOUJOURS 480p en sortie"""

    workflow = {
      "6": {
        "inputs": {
          "text": positive_prompt,
          "clip": [
            "84",
            0
          ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
          "title": "CLIP Text Encode (Positive Prompt)"
        }
      },
      "7": {
        "inputs": {
          "text": negative_prompt,
          "clip": [
            "84",
            0
          ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
          "title": "CLIP Text Encode (Negative Prompt)"
        }
      },
      "8": {
        "inputs": {
          "samples": [
            "88",
            0
          ],
          "vae": [
            "39",
            0
          ]
        },
        "class_type": "VAEDecode",
        "_meta": {
          "title": "VAE Decode"
        }
      },
      "39": {
        "inputs": {
          "vae_name": "Wan2.1_VAE.pth"
        },
        "class_type": "VAELoader",
        "_meta": {
          "title": "Charger VAE"
        }
      },
      "50": {
        "inputs": {
          "width": [
            "94",
            0
          ],
          "height": [
            "94",
            1
          ],
          "length": length,
          "batch_size": 1,
          "positive": [
            "85",
            0
          ],
          "negative": [
            "7",
            0
          ],
          "vae": [
            "39",
            0
          ],
          "start_image": [
            "52",
            0
          ]
        },
        "class_type": "WanImageToVideo",
        "_meta": {
          "title": "WanImageVersVid√©o"
        }
      },
      "52": {
        "inputs": {
          "image": "4.png"
        },
        "class_type": "LoadImage",
        "_meta": {
          "title": "Charger Image"
        }
      },
      "57": {
        "inputs": {
          "add_noise": "enable",
          "noise_seed": 868,
          "steps": 7,
          "cfg": 4,
          "sampler_name": "euler",
          "scheduler": "beta",
          "start_at_step": 0,
          "end_at_step": 4,
          "return_with_leftover_noise": "enable",
          "model": [
            "67",
            0
          ],
          "positive": [
            "50",
            0
          ],
          "negative": [
            "50",
            1
          ],
          "latent_image": [
            "50",
            2
          ]
        },
        "class_type": "KSamplerAdvanced",
        "_meta": {
          "title": "KSampler (Avanc√©)"
        }
      },
      "58": {
        "inputs": {
          "add_noise": "disable",
          "noise_seed": 0,
          "steps": 7,
          "cfg": 1,
          "sampler_name": "euler",
          "scheduler": "beta",
          "start_at_step": 4,
          "end_at_step": 1000,
          "return_with_leftover_noise": "disable",
          "model": [
            "68",
            0
          ],
          "positive": [
            "50",
            0
          ],
          "negative": [
            "50",
            1
          ],
          "latent_image": [
            "87",
            0
          ]
        },
        "class_type": "KSamplerAdvanced",
        "_meta": {
          "title": "KSampler (Avanc√©)"
        }
      },
      "61": {
        "inputs": {
          "unet_name": "Wan2.2-I2V-A14B-HighNoise-Q8_0.gguf"
        },
        "class_type": "UnetLoaderGGUF",
        "_meta": {
          "title": "Unet Loader (GGUF)"
        }
      },
      "62": {
        "inputs": {
          "unet_name": "Wan2.2-I2V-A14B-LowNoise-Q8_0.gguf"
        },
        "class_type": "UnetLoaderGGUF",
        "_meta": {
          "title": "Unet Loader (GGUF)"
        }
      },
      "64": {
        "inputs": {
          "lora_name": "Wan2.2-Lightning_I2V-A14B-4steps-lora_HIGH_fp16.safetensors",
          "strength_model": 0.9,
          "model": [
            "61",
            0
          ]
        },
        "class_type": "LoraLoaderModelOnly",
        "_meta": {
          "title": "LoraLoaderModelOnly"
        }
      },
      "66": {
        "inputs": {
          "lora_name": "Wan2.2-Lightning_I2V-A14B-4steps-lora_LOW_fp16.safetensors",
          "strength_model": 0.9,
          "model": [
            "62",
            0
          ]
        },
        "class_type": "LoraLoaderModelOnly",
        "_meta": {
          "title": "LoraLoaderModelOnly"
        }
      },
      "67": {
        "inputs": {
          "shift": 8.000000000000002,
          "model": [
            "64",
            0
          ]
        },
        "class_type": "ModelSamplingSD3",
        "_meta": {
          "title": "Mod√®le√âchantillonnageSD3"
        }
      },
      "68": {
        "inputs": {
          "shift": 8.000000000000002,
          "model": [
            "66",
            0
          ]
        },
        "class_type": "ModelSamplingSD3",
        "_meta": {
          "title": "Mod√®le√âchantillonnageSD3"
        }
      },
      "82": {
        "inputs": {
          "frame_rate": 24,
          "loop_count": 0,
          "filename_prefix": f"{datetime.now().strftime('%Y%m%d_%H%M%S')}/liro_{int(time.time())}",
          "format": "video/h264-mp4",
          "pix_fmt": "yuv420p",
          "crf": 15,
          "save_metadata": True,
          "trim_to_audio": False,
          "pingpong": False,
          "save_output": True,
          "images": [
            "83",
            0
          ]
        },
        "class_type": "VHS_VideoCombine",
        "_meta": {
          "title": "Video Combine üé•üÖ•üÖóüÖ¢"
        }
      },
      "83": {
        "inputs": {
          "ckpt_name": "rife47.pth",
          "clear_cache_after_n_frames": 10,
          "multiplier": 2,
          "fast_mode": True,
          "ensemble": True,
          "scale_factor": 1,
          "frames": [
            "8",
            0
          ]
        },
        "class_type": "RIFE VFI",
        "_meta": {
          "title": "RIFE VFI (recommend rife47 and rife49)"
        }
      },
      "84": {
        "inputs": {
          "clip_name": "umt5-xxl-encoder-Q5_K_M.gguf",
          "type": "wan"
        },
        "class_type": "CLIPLoaderGGUF",
        "_meta": {
          "title": "CLIPLoader (GGUF)"
        }
      },
      "85": {
        "inputs": {
          "value": [
            "6",
            0
          ],
          "model": [
            "84",
            0
          ]
        },
        "class_type": "UnloadModel",
        "_meta": {
          "title": "UnloadModel"
        }
      },
      "87": {
        "inputs": {
          "value": [
            "57",
            0
          ],
          "model": [
            "61",
            0
          ]
        },
        "class_type": "UnloadModel",
        "_meta": {
          "title": "UnloadModel"
        }
      },
      "88": {
        "inputs": {
          "value": [
            "58",
            0
          ],
          "model": [
            "62",
            0
          ]
        },
        "class_type": "UnloadModel",
        "_meta": {
          "title": "UnloadModel"
        }
      },
      "93": {
        "inputs": {
          "anything": [
            "82",
            0
          ]
        },
        "class_type": "easy cleanGpuUsed",
        "_meta": {
          "title": "Clean VRAM Used"
        }
      },
      "94": {
        "inputs": {
          "preset": "480p",
          "strategy": "video_mode",
          "round_to": 8,
          "image": [
            "52",
            0
          ]
        },
        "class_type": "ResizeToPresetKeepAR",
        "_meta": {
          "title": "Resize To 480p (Keep AR)"
        }
      }
    }

    return workflow


def download_image_from_url(url, save_path="temp_image.png"):
    """T√©l√©charge une image depuis une URL"""
    while True:
        try:
            with urllib.request.urlopen(url, timeout=30) as response:
                image_data = response.read()
                with open(save_path, 'wb') as f:
                    f.write(image_data)
            return save_path

        except urllib.error.URLError as e:
            print(f"Tentative √©chou√©e: {e}")
            print(f"Nouvelle tentative dans 3s...")
            time.sleep(3)

        except Exception as e:
            print(f"Erreur inattendue: {e}")
            return None


def get_target_resolution(resolution_string, original_width, original_height):
    """
    Convertit une cha√Æne de r√©solution (ex: '720p', '1080p') en tuple (width, height)
    en gardant le ratio d'aspect de la vid√©o originale.
    
    Supporte les vid√©os horizontales (16:9), verticales (9:16) et carr√©es (1:1).
    
    Args:
        resolution_string: La r√©solution cible ('480', '540', '720', '1080', '1440', '4k')
        original_width: Largeur de la vid√©o originale en pixels
        original_height: Hauteur de la vid√©o originale en pixels
    
    Returns:
        Tuple (width, height) avec le ratio d'aspect pr√©serv√©
    
    Exemples:
        - Vid√©o 1920x1080 (16:9) avec '720' ‚Üí (1280, 720)
        - Vid√©o 1080x1920 (9:16) avec '720' ‚Üí (405, 720)
        - Vid√©o 1080x1080 (1:1) avec '720' ‚Üí (720, 720)
    """
    # R√©solutions de r√©f√©rence (hauteur cible en pixels)
    resolution_map = {
        '480': 480,
        '540': 540,
        '720': 720,
        '1080': 1080,
        '1440': 1440,
        '4k': 2160,
    }
    
    if resolution_string not in resolution_map:
        raise ValueError(f"R√©solution non reconnue: {resolution_string}")
    
    target_height = resolution_map[resolution_string]
    
    # Calcul du ratio d'aspect original
    aspect_ratio = original_width / original_height
    
    # Calcul de la largeur en fonction du ratio d'aspect
    target_width = int(target_height * aspect_ratio)
    
    # Arrondir √† un multiple de 8 pour compatibilit√© avec les codecs vid√©o
    target_width = (target_width // 8) * 8
    target_height = (target_height // 8) * 8
    
    print(f"Ratio d'aspect: {aspect_ratio:.2f} ({original_width}x{original_height} ‚Üí {target_width}x{target_height})")
    
    return (target_width, target_height)


def main():
    # Initialisation du client
    client = ComfyUIClient()

    # Initialisation de l'upscaler (t√©l√©charge le mod√®le √† la premi√®re utilisation)
    print("Initialisation de RealESRGAN...")
    upscaler = VideoUpscaler(model_name='RealESRGAN_x4plus', device='cuda')

    while True:
        try:
            print("Connexion √† ComfyUI...")
            urllib.request.urlopen(f"http://127.0.0.1:18188/object_info")
            print("‚úÖ Connexion r√©ussie")
            break
        except Exception as e:
            print(f"‚ùå Erreur lors de la connexion √† ComfyUI : {e}")
            print("Nouvel essai dans 2 secondes...")
            time.sleep(2)

    while True:
        headers = {
            "Authorization": f"Bearer {os.getenv('LIRO_TOKEN')}",
        }
        while True:
            try:
                response = requests.post("https://api.liroai.com/v1/generation/next", headers=headers, timeout=30)
                break
            except Exception as e:
                time.sleep(3)

        if response.status_code == 200:
            data = response.json()
            if data:
                print(data)
                image_url = data.get("image_url")
                prompt = data.get("enchanced_prompt")
                length = data.get("length")
                generation_id = data.get("generation_id")
                resolution = int(data.get("resolution"))
                print(f"Processing generation {generation_id} with image_url: {image_url}, prompt: {prompt[:100]}..., length: {length}, target resolution: {resolution}")
            else:
                print("No generation to process")
                time.sleep(5)
                continue
        else:
            print("No generation to process")
            time.sleep(5)
            continue

        # Cr√©ation du workflow - TOUJOURS 480p
        print(f"Cr√©ation du workflow avec les param√®tres:")
        print(f"  - R√©solution source: 480p (pour la g√©n√©ration)")
        print(f"  - R√©solution cible: {resolution} (apr√®s upscaling)")
        print(f"  - Frames: {length}")
        print(f"  - Prompt: {prompt[:100]}...")

        workflow = create_workflow(
            positive_prompt=prompt,
            negative_prompt="Ëâ≤Ë∞ÉËâ≥‰∏Ω,ËøáÊõù,ÈùôÊÄÅ,ÁªÜËäÇÊ®°Á≥ä‰∏çÊ∏Ö,Â≠óÂπï,È£éÊ†º,‰ΩúÂìÅ,Áîª‰Ωú,ÁîªÈù¢,ÈùôÊ≠¢,Êï¥‰ΩìÂèëÁÅ∞,ÊúÄÂ∑ÆË¥®Èáè,‰ΩéË¥®Èáè,JPEGÂéãÁº©ÊÆãÁïô,‰∏ëÈôãÁöÑ,ÊÆãÁº∫ÁöÑ,Â§ö‰ΩôÁöÑÊâãÊåá,ÁîªÂæó‰∏çÂ•ΩÁöÑÊâãÈÉ®,ÁîªÂæó‰∏çÂ•ΩÁöÑËÑ∏ÈÉ®,Áï∏ÂΩ¢ÁöÑ,ÊØÅÂÆπÁöÑ,ÂΩ¢ÊÄÅÁï∏ÂΩ¢ÁöÑËÇ¢‰Ωì,ÊâãÊåáËûçÂêà,ÈùôÊ≠¢‰∏çÂä®ÁöÑÁîªÈù¢,ÊÇ≤‰π±ÁöÑËÉåÊôØ,‰∏âÊù°ËÖø,ËÉåÊôØ‰∫∫ÂæàÂ§ö,ÂÄíÁùÄËµ∞, slow motion",
            input_image="temp_placeholder.png",
            resolution=480,
            length=length,
        )

        print(f"\nT√©l√©chargement de l'image depuis: {image_url}")
        local_image_path = download_image_from_url(image_url)

        if not local_image_path:
            print("√âchec du t√©l√©chargement de l'image. Arr√™t.")
            continue

        print(f"Upload de l'image vers ComfyUI...")
        upload_response = client.upload_image(local_image_path)
        uploaded_filename = upload_response.get('name', local_image_path)
        print(f"Image upload√©e: {uploaded_filename}")

        # Mise √† jour du workflow avec le nom du fichier upload√©
        workflow['52']['inputs']['image'] = uploaded_filename

        # Envoi du workflow
        print("\nEnvoi du workflow √† ComfyUI...")
        response = client.queue_prompt(workflow)
        prompt_id = response['prompt_id']
        print(f"Workflow en queue avec ID: {prompt_id}")

        # Attente de la compl√©tion
        print("G√©n√©ration en cours... (cela peut prendre plusieurs minutes)")
        result = client.wait_for_completion(prompt_id)

        print("\n‚úì G√©n√©ration ComfyUI termin√©e!")

        # R√©cup√©ration et traitement de la vid√©o g√©n√©r√©e
        if 'outputs' in result and '82' in result['outputs']:
            videos = result['outputs']['82'].get('gifs', [])
            for video in videos:
                filename = video['filename']
                subfolder = video.get('subfolder', '')
                input_video_path = f"/workspace/ComfyUI/output/{subfolder}/{filename}" if subfolder else f"/workspace/ComfyUI/output/{filename}"
                
                print(f"‚úì Vid√©o g√©n√©r√©e: {filename}")
                print(f"  Emplacement: {input_video_path}")

                # Upscaling de la vid√©o
                try:
                    # R√©cup√©rer les dimensions originales de la vid√©o g√©n√©r√©e
                    cap = cv2.VideoCapture(input_video_path)
                    original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                    original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                    cap.release()
                    
                    # Obtenir la r√©solution cible en pr√©servant le ratio d'aspect
                    target_res = get_target_resolution(str(resolution), original_width, original_height)
                    output_video_path = input_video_path.replace('.mp4', '_upscaled.mp4')
                    
                    print(f"\nD√©marrage de l'upscaling vers {resolution}p...")
                    upscaler.upscale_video(input_video_path, output_video_path, target_resolution=target_res)
                    print(f"‚úì Upscaling termin√©!")
                    
                except Exception as e:
                    print(f"Erreur lors de l'upscaling: {e}")
                    output_video_path = input_video_path

                # Upload de la vid√©o upscal√©e
                try:
                    with open(output_video_path, "rb") as f:
                        r = requests.post(
                            "https://cdn.liroai.com/upload.php",
                            headers=headers,
                            files={"file": (output_video_path, f)}
                        )
                    r.raise_for_status()
                    data = r.json()
                    print("Lien du fichier:", data["url"])
                    
                    # Mise √† jour de l'API avec le lien de la vid√©o
                    update_response = requests.post(
                        "https://api.liroai.com/v1/generation/finished",
                        headers=headers,
                        data={"generation_id": generation_id, "result_url": data["url"]}
                    )
                    print(update_response)
                    if update_response.status_code == 200:
                        print("API mise √† jour avec succ√®s")
                    else:
                        print("√âchec de la mise √† jour de l'API:", update_response.text)
                except requests.exceptions.RequestException as e:
                    print("Erreur r√©seau ou HTTP:", e)
                except ValueError:
                    print("La r√©ponse n'√©tait pas du JSON valide")
        else:
            print("Aucune vid√©o trouv√©e dans les r√©sultats")

        # Nettoyage
        if os.path.exists(local_image_path):
            os.remove(local_image_path)
            print(f"\nFichier temporaire nettoy√©: {local_image_path}")


if __name__ == "__main__":
    main()
